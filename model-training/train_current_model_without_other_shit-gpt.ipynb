{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ffa4a6-9761-4dd4-ace5-40db50902d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import ZeroShotClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import spacy\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Set up Plotly renderer\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "# Set up environment variables for AWS\n",
    "AWS_DEFAULT_REGION = os.environ[\"AWS_DEFAULT_REGION\"]\n",
    "AWS_ACCESS_KEY_ID = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "AWS_SECRET_ACCESS_KEY = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "\n",
    "# Load Spacy model for lemmatization\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function for lemmatization\n",
    "def lemmatization(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)    \n",
    "    return lemmatized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90bfd5e-a45b-4fa3-b638-6e023da28b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the mounted volume (Replace with your data path)\n",
    "data_path = '/review_classification_project/alarmy_reviews.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "print(f\"Data Loaded. Shape: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df5babe-918b-471d-af2b-2d628fe9d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing content\n",
    "data = data.dropna(subset=['text'])\n",
    "\n",
    "# Apply lemmatization\n",
    "data['preprocessed_content'] = data['text'].apply(lemmatization)\n",
    "\n",
    "# Drop rows with missing lemmatized content\n",
    "data = data.dropna(subset=['preprocessed_content'])\n",
    "print(f\"Data Preprocessed. Shape after cleaning: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b608871-598f-41b0-a9f3-32f270804cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of known topics for zero-shot classification\n",
    "zeroshot_topic_list = [\n",
    "    \"android\", \"premium\", \"ads\", \"math\", \"subscription\", \"update\", \"camera\", \n",
    "    \"shake\", \"weather\", 'snooze', 'loud', 'doesn', 'off'\n",
    "]\n",
    "\n",
    "# Prepare documents for BERTopic\n",
    "docs = list(data.preprocessed_content.values)\n",
    "\n",
    "# Set up ZeroShotClassification model\n",
    "representation_model = ZeroShotClassification(zeroshot_topic_list, model=\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")\n",
    "\n",
    "# Create and train the BERTopic model\n",
    "topic_model = BERTopic(\n",
    "    zeroshot_topic_list=zeroshot_topic_list,\n",
    "    zeroshot_min_similarity=.85,\n",
    "    representation_model=representation_model,\n",
    "    nr_topics=50\n",
    ")\n",
    "\n",
    "# Fit the BERTopic model on the documents\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "print(\"Topic modeling completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f6694d-1307-4aa0-8256-9fca128b32cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic information\n",
    "topic_info = topic_model.get_topic_info()\n",
    "display(topic_info)\n",
    "\n",
    "# Visualize top topics as a bar chart\n",
    "fig = topic_model.visualize_barchart(top_n_topics=60, n_words=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74d593-852f-4ff3-bf51-db07b0b4d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a specific topic number to analyze\n",
    "topic_number = 25\n",
    "\n",
    "# Display top words for the selected topic\n",
    "print(f\"Top words for topic {topic_number}:\")\n",
    "print(topic_model.get_topic(topic_number))\n",
    "\n",
    "# Extract 10 example reviews for the chosen topic\n",
    "topic_indices = [i for i, t in enumerate(topics) if t == topic_number]\n",
    "example_reviews = [docs[i] for i in topic_indices[:10]]\n",
    "print(f\"\\n10 Example Reviews for Topic {topic_number}:\\n\")\n",
    "for idx, review in enumerate(example_reviews, 1):\n",
    "    print(f\"Review {idx}: {review}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3508d-9f95-4bc5-8ece-ad472d5ed059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate topic distances using cosine similarity\n",
    "distance_matrix = cosine_similarity(np.array(topic_model.topic_embeddings_))\n",
    "dist_df = pd.DataFrame(distance_matrix, columns=topic_model.topic_labels_.values(), \n",
    "                       index=topic_model.topic_labels_.values())\n",
    "\n",
    "# Extract pairwise topic distances and sort\n",
    "tmp = []\n",
    "for rec in dist_df.reset_index().to_dict('records'):\n",
    "    t1 = rec['index']\n",
    "    for t2 in rec:\n",
    "        if t2 == 'index': \n",
    "            continue\n",
    "        tmp.append({'topic1': t1, 'topic2': t2, 'distance': rec[t2]})\n",
    "\n",
    "pair_dist_df = pd.DataFrame(tmp)\n",
    "pair_dist_df = pair_dist_df[(pair_dist_df.topic1.map(lambda x: not x.startswith('-1'))) & \n",
    "                            (pair_dist_df.topic2.map(lambda x: not x.startswith('-1')))]\n",
    "pair_dist_df = pair_dist_df[pair_dist_df.topic1 < pair_dist_df.topic2]\n",
    "pair_dist_df.sort_values('distance', ascending=False).head(50)\n",
    "\n",
    "# Merge closely related topics\n",
    "topic_model.merge_topics(docs, [[10, 3, 37], [2, 13, 15, 19], [12, 30, 25], \n",
    "                                [4, 5, 7, 20, 21, 27, 28, 29, 33, 36, 43, 44, 46], \n",
    "                                [1, 17, 31, 34, 40], [9, 26, 41], [18, 40]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b950c-29b3-40b1-bc47-dc530602b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set human-readable topic labels\n",
    "topic_labels_dict = {\n",
    "    0: \"Math\", 1: \"Sometimes not Ringing\", 2: \"Good App\", 3: \"Premium Subscription\",\n",
    "    4: \"Loud\", 5: \"Take Photo\", 6: \"Snooze\", 7: \"Easy to Use\", 8: \"Barcode Scanner\",\n",
    "    9: \"Update\", 10: \"Shake Mission\", 11: \"Horoscope/News\", 12: \"Overheating\", 13: \"Storage Size\", 14: \"Challenges\"\n",
    "}\n",
    "topic_model.set_topic_labels(topic_labels_dict)\n",
    "\n",
    "# Save the model to HuggingFace\n",
    "login(os.getenv(\"HUGGINGFACE_TOKEN\"))\n",
    "topic_model.push_to_hf_hub(repo_id=\"DobreMihai/bertopic_ready_labeled\", save_ctfidf=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
